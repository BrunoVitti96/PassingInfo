{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vX_Bln77F5O_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "84BQACpAFz08"
      },
      "outputs": [],
      "source": [
        "gemini_api = 'AIzaSyC769yI6kwfatZoqftMx9lUUVbrmijuWjM'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "collapsed": true,
        "id": "JyXc-pjOGxL2",
        "outputId": "531c00ae-87b0-48d5-985f-17c7a3e53ef2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langgraph\n",
            "  Downloading langgraph-0.3.20-py3-none-any.whl.metadata (7.7 kB)\n",
            "Requirement already satisfied: langchain-core<0.4,>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.47)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.23-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt<0.2,>=0.1.1 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.7-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk<0.2.0,>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.59-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting xxhash<4.0.0,>=3.5.0 (from langgraph)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (0.3.18)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (4.12.2)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4,>=0.1->langgraph) (2.10.6)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.15)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (2025.1.31)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.0.7)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.32.3)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.1->langgraph) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<0.4,>=0.1->langgraph) (2.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk<0.2.0,>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langgraph-0.3.20-py3-none-any.whl (137 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.9/137.9 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_checkpoint-2.0.23-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.7-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.59-py3-none-any.whl (47 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.0/47.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.7/223.7 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph\n",
            "Successfully installed langgraph-0.3.20 langgraph-checkpoint-2.0.23 langgraph-prebuilt-0.1.7 langgraph-sdk-0.1.59 ormsgpack-1.9.0 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First, import the necessary modules from LangGraph and Python standard libraries.\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from typing_extensions import TypedDict\n",
        "from typing import List, Annotated\n",
        "import operator\n"
      ],
      "metadata": {
        "id": "6Z4zUJC-GTGq"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------\n",
        "# Step 1: Define the Graph State\n",
        "# -------------------------------\n",
        "#\n",
        "# In LangGraph you define a “state” that holds all the data shared between nodes.\n",
        "# Here we define a simple state that holds a list of messages.\n",
        "# The use of \"Annotated\" with operator.add means that when a node returns new messages,\n",
        "# they will be appended to the existing list (instead of replacing it).\n",
        "\n",
        "class MyState(TypedDict):\n",
        "    messages: Annotated[List[str], operator.add]\n"
      ],
      "metadata": {
        "id": "JpKhTOx7GYuH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------\n",
        "# Step 2: Define the Node Functions\n",
        "# -------------------------------\n",
        "#\n",
        "# Each node is a Python function.\n",
        "# They accept a state (a dictionary matching our MyState schema) and return an update.\n",
        "# We’ll define four nodes:\n",
        "#\n",
        "# 1. node_start: Gets an initial user message.\n",
        "# 2. node_process: Processes that message (e.g. appends extra text).\n",
        "# 3. function_node: A node that “executes a function” (for example, it could call a tool).\n",
        "# 4. prompt_node: A node that simulates asking a prompt (for example, a different type of response).\n",
        "\n",
        "# Node 1: Start node – receives an input message.\n",
        "def node_start(state: MyState):\n",
        "    # We expect an extra key 'user_message' in the state;\n",
        "    # if not present, we use a default.\n",
        "    user_message = state.get('user_message', 'Hello')\n",
        "    # We create a message that records what the user said.\n",
        "    new_msg = f\"User said: {user_message}\"\n",
        "    return {\"messages\": [new_msg]}\n"
      ],
      "metadata": {
        "id": "e0C-dI3lGcxx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Node 2: Process node – processes the previous message.\n",
        "def node_process(state: MyState):\n",
        "    # Retrieve the last message from the state.\n",
        "    last_msg = state[\"messages\"][-1]\n",
        "    # Process it by appending extra text.\n",
        "    processed_msg = last_msg + \" - Processed\"\n",
        "    return {\"messages\": [processed_msg]}\n",
        "\n",
        "# Node 3: Function node – executed if the condition is met.\n",
        "def function_node(state: MyState):\n",
        "    # This node simulates executing a function (for example, a tool call).\n",
        "    return {\"messages\": [\"Function executed: Condition was True!\"]}\n",
        "\n",
        "# Node 4: Prompt node – executed if the condition is not met.\n",
        "def prompt_node(state: MyState):\n",
        "    # This node simulates a different behavior, for example returning a prompt message.\n",
        "    return {\"messages\": [\"Prompt executed: Condition was False, so here is an alternative response.\"]}\n"
      ],
      "metadata": {
        "id": "a2tIlM3iGh58"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------\n",
        "# Step 3: Define the Conditional Edge Function\n",
        "# -------------------------------\n",
        "#\n",
        "# A conditional edge function examines the current state and returns a key.\n",
        "# In our case, we’ll check the last (processed) message.\n",
        "# For example, if the length of the processed message is an even number, we choose the \"function\" node;\n",
        "# if odd, we choose the \"prompt\" node.\n",
        "\n",
        "def condition_func(state: MyState):\n",
        "    processed_msg = state[\"messages\"][-1]\n",
        "    if len(processed_msg) % 2 == 0:\n",
        "        return \"function\"\n",
        "    else:\n",
        "        return \"prompt\"\n"
      ],
      "metadata": {
        "id": "CuavIX0mGld9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------\n",
        "# Step 4: Build the Graph\n",
        "# -------------------------------\n",
        "#\n",
        "# Now we create a StateGraph with our state schema, add our nodes,\n",
        "# define the edges (including the conditional edge), and compile the graph.\n",
        "\n",
        "# Create a new graph using our state schema.\n",
        "graph = StateGraph(MyState)\n",
        "\n",
        "# Add nodes to the graph with a unique string name and the corresponding function.\n",
        "graph.add_node(\"start\", node_start)\n",
        "graph.add_node(\"process\", node_process)\n",
        "graph.add_node(\"function\", function_node)\n",
        "graph.add_node(\"prompt\", prompt_node)\n",
        "\n",
        "# Set the entry point of the graph. This is the first node to run.\n",
        "graph.set_entry_point(\"start\")\n",
        "\n",
        "# Add a normal edge from \"start\" to \"process\" so that after the start node, the process node runs.\n",
        "graph.add_edge(\"start\", \"process\")\n",
        "\n",
        "# Add a conditional edge from the \"process\" node.\n",
        "# The function condition_func will be called after \"process\" executes.\n",
        "# Based on its return value (\"function\" or \"prompt\"), the graph will next run that node.\n",
        "graph.add_conditional_edges(\"process\", condition_func, {\"function\": \"function\", \"prompt\": \"prompt\"})\n",
        "\n",
        "# Finally, once either \"function\" or \"prompt\" has run, we signal the end of execution.\n",
        "graph.add_edge(\"function\", END)\n",
        "graph.add_edge(\"prompt\", END)\n",
        "\n",
        "# Compile the graph into a runnable object.\n",
        "compiled_graph = graph.compile()\n"
      ],
      "metadata": {
        "id": "hq0Qe-hRGrSL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# -------------------------------\n",
        "# Step 5: Run the Graph\n",
        "# -------------------------------\n",
        "#\n",
        "# To run the graph, we prepare an initial state.\n",
        "# Here we provide a user_message and an initially empty list of messages.\n",
        "initial_state = {\n",
        "    \"user_message\": \"Hi there!\",\n",
        "    \"messages\": []  # start with an empty list\n",
        "}\n",
        "\n",
        "# Invoke the compiled graph with the initial state.\n",
        "result_state = compiled_graph.invoke(initial_state)\n",
        "\n",
        "# Print the final state to see the result.\n",
        "print(\"Final state:\")\n",
        "print(result_state)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Um-ahpZ-GMp4",
        "outputId": "9ec96826-6881-41be-86c4-66a79da6c1f1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final state:\n",
            "{'messages': ['User said: Hello', 'User said: Hello - Processed', 'Function executed: Condition was True!']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0NnxJhucG7_S"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
